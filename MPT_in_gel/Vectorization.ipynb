{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stat\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import numpy.linalg as la\n",
    "\n",
    "pi = np.pi\n",
    "sin = np.sin\n",
    "cos = np.cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mike_mckenna/Desktop/brain-diffusion/Chad_functions_and_unittests'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from MSD_utils import get_data_pups, build_time_array, return_average, avg_all, graph_single_variable\n",
    "from MSD_utils import SD_all, return_SD, range_and_ticks, choose_y_axis_params, data_prep_for_plotting_pups\n",
    "from MSD_utils import fill_in_and_split, plot_traj_length_histogram, plot_traj, filter_out_short_traj\n",
    "from MSD_utils import plot_trajectory_overlay, quality_control\n",
    "\n",
    "from MSD_utils import diffusion_coefficient_point_derivative, diffusion_coefficient_linear_regression\n",
    "from MSD_utils import calculate_diffusion_coefficients, diffusion_bar_chart, summary_barcharts\n",
    "from MSD_utils import calculate_MMSDs, plot_general_histogram, plot_MSD_histogram, plot_all_MSD_histograms\n",
    "from MSD_utils import fillin2, MSD_iteration, vectorized_MMSD_calcs\n",
    "from MSD_utils import get_data_gels, data_prep_for_plotting_gels, plot_all_MSD_histograms_gels, quality_control_gels\n",
    "from MSD_utils import calculate_diffusion_coefficients_gels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"./Data_Files_Mike/9_15_17 - MPT cooling rate effects - cold/well_1/\"\n",
    "path = \"./Data_Files_Mike/9_15_17 - MPT cooling rate effects - cold/well_1/geoM2xy_{sample_name}.csv\"\n",
    "frames = 480\n",
    "SD_frames = [1, 10, 19, 28]\n",
    "conversion = (0.16, 9.91, 1)#(0.3, 3.95, 1)\n",
    "to_frame = 480\n",
    "dimension = \"2D\"\n",
    "time_to_calculate = 1\n",
    "\n",
    "base = \"0-8p_agarose\"\n",
    "base_name = \"YG\"\n",
    "test_bins = np.linspace(0, 75, 76)\n",
    "\n",
    "# name = 'RED_KO_PEG_P1_S1_cortex'\n",
    "cut = 2\n",
    "totvids = 10\n",
    "frame_m = 480  # atm I can't go lower than the actual value.\n",
    "conversion = (0.16, 9.91, 1)\n",
    "\n",
    "parameters = {}\n",
    "parameters[\"channels\"] = [\"PS\"]\n",
    "#parameters[\"genotypes\"] = [\"WT\"]\n",
    "#parameters[\"pups\"] = [\"P1\", \"P2\", \"P3\"]\n",
    "parameters[\"surface functionalities\"] = [\"COOH\"]\n",
    "parameters[\"slices\"] = [\"1\"]\n",
    "#parameters[\"regions\"] = [\"cortex\"]\n",
    "parameters[\"replicates\"] = [1, 2, 3, 4]\n",
    "parameters[\"slice suffixes\"] = ['a', 'b', 'c']\n",
    "\n",
    "\n",
    "channels = parameters[\"channels\"]\n",
    "#genotypes = parameters[\"genotypes\"]\n",
    "#pups = parameters[\"pups\"]\n",
    "surface_functionalities = parameters[\"surface functionalities\"]\n",
    "slices = parameters[\"slices\"]\n",
    "#regions = parameters[\"regions\"]\n",
    "replicates = parameters[\"replicates\"]\n",
    "suffixes = parameters[\"slice suffixes\"]\n",
    "\n",
    "y_range, ticks_y, dec_y, x_range, ticks_x, dec_x = 8, 2, 1, 3, 1, 1\n",
    "frames = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total particles after merging datasets and filtering short trajectories: 14979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mike_mckenna/Downloads/Users/mike_mckenna/Desktop/lib/python3.5/site-packages/scipy/stats/stats.py:314: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    }
   ],
   "source": [
    "geoM1x = {}\n",
    "geoM1y = {}\n",
    "geoM2xy = {}\n",
    "SM1x = {}\n",
    "SM1y = {}\n",
    "SM2xy = {}\n",
    "\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            suffix = suffixes[slice_counter]\n",
    "            sample_name = \"{}_{}_section_1_vid_{}\".format(channel, surface_functionality, slic)\n",
    "            DIR = folder.format(functionality = surface_functionality, slic = slic)\n",
    "            frames, total1, xs, ys, x, y = MSD_iteration(DIR, sample_name, cut, totvids, conversion, frame_m, suffix)\n",
    "\n",
    "            geoM1x[sample_name], geoM1y[sample_name], geoM2xy[sample_name], SM1x[sample_name], SM1y[sample_name],\\\n",
    "                SM2xy[sample_name] = vectorized_MMSD_calcs(frames, total1, xs, ys, x, y, frame_m)\n",
    "            np.savetxt(DIR+'geoM2xy_{}.csv'.format(sample_name), geoM2xy[sample_name], delimiter=',')\n",
    "            np.savetxt(DIR+'SM2xy_{}.csv'.format(sample_name), SM2xy[sample_name], delimiter=',')\n",
    "\n",
    "            slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"./Data_Files_Mike/9_6_17 - MPT in brain sections/PS_PEG/\"\n",
    "path = \"./Data_Files_Mike/9_6_17 - MPT in brain sections/PS_PEG/geoM2xy_{sample_name}.csv\"\n",
    "frames = 480\n",
    "SD_frames = [1, 10, 19, 28]\n",
    "conversion = (0.16, 9.91, 1)#(0.3, 3.95, 1)\n",
    "to_frame = 480\n",
    "dimension = \"2D\"\n",
    "time_to_calculate = 1\n",
    "\n",
    "base = \"0-8p_agarose\"\n",
    "base_name = \"YG\"\n",
    "test_bins = np.linspace(0, 75, 76)\n",
    "\n",
    "# name = 'RED_KO_PEG_P1_S1_cortex'\n",
    "cut = 2\n",
    "totvids = 11\n",
    "frame_m = 480  # atm I can't go lower than the actual value.\n",
    "conversion = (0.16, 9.91, 1)\n",
    "\n",
    "parameters = {}\n",
    "parameters[\"channels\"] = [\"PS\"]\n",
    "#parameters[\"genotypes\"] = [\"WT\"]\n",
    "#parameters[\"pups\"] = [\"P1\", \"P2\", \"P3\"]\n",
    "parameters[\"surface functionalities\"] = [\"PEG\"]\n",
    "parameters[\"slices\"] = [\"1\"]\n",
    "#parameters[\"regions\"] = [\"cortex\"]\n",
    "parameters[\"replicates\"] = [1, 2, 3, 4]\n",
    "parameters[\"slice suffixes\"] = ['a', 'b', 'c']\n",
    "\n",
    "\n",
    "channels = parameters[\"channels\"]\n",
    "#genotypes = parameters[\"genotypes\"]\n",
    "#pups = parameters[\"pups\"]\n",
    "surface_functionalities = parameters[\"surface functionalities\"]\n",
    "slices = parameters[\"slices\"]\n",
    "#regions = parameters[\"regions\"]\n",
    "replicates = parameters[\"replicates\"]\n",
    "suffixes = parameters[\"slice suffixes\"]\n",
    "\n",
    "y_range, ticks_y, dec_y, x_range, ticks_x, dec_x = 8, 2, 1, 3, 1, 1\n",
    "frames = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total particles after merging datasets and filtering short trajectories: 59518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mike_mckenna/Downloads/Users/mike_mckenna/Desktop/lib/python3.5/site-packages/scipy/stats/stats.py:314: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    }
   ],
   "source": [
    "geoM1x = {}\n",
    "geoM1y = {}\n",
    "geoM2xy = {}\n",
    "SM1x = {}\n",
    "SM1y = {}\n",
    "SM2xy = {}\n",
    "\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            suffix = suffixes[slice_counter]\n",
    "            sample_name = \"{}_{}_section_2_vid_{}\".format(channel, surface_functionality, slic)\n",
    "            DIR = folder.format(functionality = surface_functionality, slic = slic)\n",
    "            frames, total1, xs, ys, x, y = MSD_iteration(DIR, sample_name, cut, totvids, conversion, frame_m, suffix)\n",
    "\n",
    "            geoM1x[sample_name], geoM1y[sample_name], geoM2xy[sample_name], SM1x[sample_name], SM1y[sample_name],\\\n",
    "                SM2xy[sample_name] = vectorized_MMSD_calcs(frames, total1, xs, ys, x, y, frame_m)\n",
    "            np.savetxt(DIR+'geoM2xy_{}.csv'.format(sample_name), geoM2xy[sample_name], delimiter=',')\n",
    "            np.savetxt(DIR+'SM2xy_{}.csv'.format(sample_name), SM2xy[sample_name], delimiter=',')\n",
    "\n",
    "            slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, avg_over_slices, time, time_SD, average_over_slices, all_SD_over_slices = \\\n",
    "    data_prep_for_plotting_gels(path, frames, SD_frames, conversion, to_frame, parameters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all_MSD_histograms_gels(parameters, folder, SM2xy, time, test_bins, 1, set_y_limit=True, y_range=5000, set_x_limit=True, x_range=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"./{functionality}/{slic}/\"\n",
    "path = \"./{functionality}/{slic}/geoM2xy_{sample_name}.csv\"\n",
    "path2 = \"./{functionality}/{slic}/Traj_{sample_name}.tif.csv\"\n",
    "\n",
    "frames = 120\n",
    "SD_frames2 = [1, 2, 3, 4]\n",
    "conversion = (1.24, 1.93, 1)#(0.3, 3.95, 1)\n",
    "to_frame = 60\n",
    "dimension = \"2D\"\n",
    "time_to_calculate = 1\n",
    "\n",
    "base = \"0-2p_agarose\"\n",
    "base_name = \"RED\"\n",
    "test_bins = np.linspace(0, 75, 76)\n",
    "\n",
    "# name = 'RED_KO_PEG_P1_S1_cortex'\n",
    "cut = 4\n",
    "totvids = 10\n",
    "frame_m = 120  # atm I can't go lower than the actual value.\n",
    "\n",
    "parameters = {}\n",
    "parameters[\"channels\"] = [\"RED\"]\n",
    "parameters[\"surface functionalities\"] = [\"nPEG\"]\n",
    "parameters[\"slices\"] = [\"1\", \"2\", \"3\", \"4\"]\n",
    "parameters[\"replicates\"] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "parameters[\"slice suffixes\"] = ['a', 'b', 'c', 'd']\n",
    "\n",
    "\n",
    "channels = parameters[\"channels\"]\n",
    "surface_functionalities = parameters[\"surface functionalities\"]\n",
    "slices = parameters[\"slices\"]\n",
    "replicates = parameters[\"replicates\"]\n",
    "suffixes = parameters[\"slice suffixes\"]\n",
    "\n",
    "frames2 = 120\n",
    "interv = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geoM1x = {}\n",
    "geoM1y = {}\n",
    "geoM2xy = {}\n",
    "SM1x = {}\n",
    "SM1y = {}\n",
    "SM2xy = {}\n",
    "\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            suffix = suffixes[slice_counter]\n",
    "            sample_name = \"{}_{}_0-2p_agarose_{}\".format(channel, surface_functionality, slic)\n",
    "            DIR = folder.format(functionality = surface_functionality, slic = slic)\n",
    "            frames, total1, xs, ys, x, y = MSD_iteration(DIR, sample_name, cut, totvids, conversion, frame_m, suffix)\n",
    "\n",
    "            geoM1x[sample_name], geoM1y[sample_name], geoM2xy[sample_name], SM1x[sample_name], SM1y[sample_name],\\\n",
    "                SM2xy[sample_name] = vectorized_MMSD_calcs(frames, total1, xs, ys, x, y, frame_m)\n",
    "            np.savetxt(DIR+'geoM2xy_{}.csv'.format(sample_name), geoM2xy[sample_name], delimiter=',')\n",
    "            np.savetxt(DIR+'SM2xy_{}.csv'.format(sample_name)), SM2xy[sample_name], delimiter=',')\n",
    "\n",
    "            slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2, avg_over_slices2, time2, time_SD2, average_over_slices2, all_SD_over_slices2 = \\\n",
    "    data_prep_for_plotting_gels(path, frames2, SD_frames2, conversion, to_frame, parameters, base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all_MSD_histograms_gels(parameters, base, folder, SM2xy, time2, test_bins, 1, set_y_limit=True, y_range=5000, set_x_limit=True, x_range=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_control_gels(path2, folder, frames, conversion, parameters, base, interv, cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quality_control_gels(path2, folder, frames, conversion, parameters, base, interv, cut):\n",
    "    \"\"\"\n",
    "    This function plots a histogram of trajectory lengths (in units of frames) and two types of plots of\n",
    "    trajectories (original and overlay).\n",
    "\n",
    "    Inputs:\n",
    "    path2: string.  Name of input trajectory csv files.\n",
    "    folder: string. Name of folder to which to save results.\n",
    "    frames: integer.  Total number of frames in videos.\n",
    "    conversion: array.  Contains microns per pixel and frames per second of videos.\n",
    "    parameters:\n",
    "\n",
    "    parameters = {}\n",
    "    parameters[\"channels\"] = [\"RED\"]\n",
    "    parameters[\"surface functionalities\"] = [\"PEG\"]\n",
    "    parameters[\"slices\"] = [\"S1\", \"S2\", \"S3\"]\n",
    "    parameters[\"replicates\"] = [1, 2, 3, 4]\n",
    "\n",
    "    cut: integer.  Minimum number of frames a trajectory must have in order to be plotted.\n",
    "    \"\"\"\n",
    "\n",
    "    channels = parameters[\"channels\"]\n",
    "    surface_functionalities = parameters[\"surface functionalities\"]\n",
    "    slices = parameters[\"slices\"]\n",
    "    replicates = parameters[\"replicates\"]\n",
    "    SD_frames = [1, 7, 14, 15]\n",
    "\n",
    "    trajectory = {}\n",
    "    names_with_replicates = {}\n",
    "    data = {}\n",
    "\n",
    "    particles_unfiltered = {}\n",
    "    framed_unfiltered = {}\n",
    "    x_data_unfiltered = {}\n",
    "    y_data_unfiltered = {}\n",
    "    total_unfiltered = {}\n",
    "    particles = {}\n",
    "    framed = {}\n",
    "    x_data = {}\n",
    "    y_data = {}\n",
    "    total = {}\n",
    "    tlength = {}\n",
    "    x_microns = {}\n",
    "    y_microns = {}\n",
    "    x_particle = {}\n",
    "    y_particle = {}\n",
    "\n",
    "    x_original_frames = {}\n",
    "    y_original_frames = {}\n",
    "\n",
    "    x_adjusted_frames = {}\n",
    "    y_adjusted_frames = {}\n",
    "\n",
    "    counter2 = 0\n",
    "\n",
    "    for channel in channels:\n",
    "            for surface_functionality in surface_functionalities:\n",
    "                        for slic in slices:\n",
    "                            for replicate in replicates:\n",
    "                                # Establishing sample names and extracting data from csv files.\n",
    "                                counter2 = counter2 + 1\n",
    "                                sample_name_long = \"{}_{}_{}_{}_{}\".format(channel, surface_functionality, base, slic, replicate)\n",
    "                                names_with_replicates[counter2] = sample_name_long\n",
    "\n",
    "                                filename = path2.format(functionality = surface_functionality, slic = slic, sample_name=sample_name_long)\n",
    "                                data[sample_name_long] = np.genfromtxt(filename, delimiter=\",\")\n",
    "                                data[sample_name_long] = np.delete(data[sample_name_long], 0, 1)\n",
    "\n",
    "                                # Names of output plots\n",
    "                                fold = folder.format(functionality = surface_functionality, slic = slic)\n",
    "                                \n",
    "                                logplot = fold +'{}_logplot'.format(sample_name_long)\n",
    "                                Mplot = fold +'{}_Mplot'.format(sample_name_long)\n",
    "                                Dplot = fold +'{}_Dplot'.format(sample_name_long)\n",
    "                                Hplot = fold +'{}_Hplot'.format(sample_name_long)\n",
    "                                Hlogplot = fold +'{}_Hlogplot'.format(sample_name_long)\n",
    "                                Cplot = fold +'{}_Cplot'.format(sample_name_long)\n",
    "                                Tplot = fold +'{}_Tplot'.format(sample_name_long)\n",
    "                                T2plot = fold +'{}_T2plot'.format(sample_name_long)\n",
    "                                lenplot = fold +'{}_lenplot'.format(sample_name_long)\n",
    "\n",
    "                                # Fill in data and split into individual trajectories\n",
    "                                particles_unfiltered[counter2], framed_unfiltered[counter2], x_data_unfiltered[counter2],\\\n",
    "                                    y_data_unfiltered[counter2] = fill_in_and_split(data[names_with_replicates[counter2]])\n",
    "\n",
    "                                total_unfiltered[counter2] = int(max(particles_unfiltered[counter2]))\n",
    "\n",
    "                                # Filter out short trajectories\n",
    "                                particles[counter2], framed[counter2], x_data[counter2], y_data[counter2] =\\\n",
    "                                    filter_out_short_traj(particles_unfiltered[counter2], framed_unfiltered[counter2],\n",
    "                                                          x_data_unfiltered[counter2], y_data_unfiltered[counter2], cut)\n",
    "\n",
    "                                # Convert to microns and seconds\n",
    "                                time, time_SD = build_time_array(frames, conversion, SD_frames)\n",
    "                                framen = np.linspace(0, frames, frames+1).astype(np.int64)\n",
    "                                total[counter2] = int(max(particles[counter2]))\n",
    "                                tlength[counter2] = np.zeros(total[counter2])\n",
    "\n",
    "                                x_microns[counter2] = x_data[counter2]*conversion[0]\n",
    "                                y_microns[counter2] = y_data[counter2]*conversion[0]\n",
    "\n",
    "                                # Adjust frames (probably unneccesary, but I did it...)\n",
    "                                x_particle[counter2] = {}\n",
    "                                y_particle[counter2] = {}\n",
    "\n",
    "                                x_original_frames[counter2] = {}\n",
    "                                y_original_frames[counter2] = {}\n",
    "\n",
    "                                x_adjusted_frames[counter2] = {}\n",
    "                                y_adjusted_frames[counter2] = {}\n",
    "\n",
    "                                for num in range(1, total[counter2] + 1):\n",
    "                                    hold = np.where(particles[counter2] == num)\n",
    "                                    itindex = hold[0]\n",
    "                                    min1 = min(itindex)\n",
    "                                    max1 = max(itindex)\n",
    "                                    x_particle[counter2][num] = x_microns[counter2][min1:max1+1]\n",
    "                                    y_particle[counter2][num] = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_original_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    y_original_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    x_adjusted_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    y_adjusted_frames[counter2][num] = np.zeros(frames + 1)\n",
    "\n",
    "                                    x_original_frames[counter2][num][framed[counter2][min1]:framed[counter2][max1]+1]\\\n",
    "                                        = x_microns[counter2][min1:max1+1]\n",
    "                                    y_original_frames[counter2][num][framed[counter2][min1]:framed[counter2][max1]+1]\\\n",
    "                                        = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_adjusted_frames[counter2][num][0:max1+1-min1] = x_microns[counter2][min1:max1+1]\n",
    "                                    y_adjusted_frames[counter2][num][0:max1+1-min1] = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_original_frames[counter2][num] = ma.masked_equal(x_original_frames[counter2][num], 0)\n",
    "                                    y_original_frames[counter2][num] = ma.masked_equal(y_original_frames[counter2][num], 0)\n",
    "                                    x_adjusted_frames[counter2][num] = ma.masked_equal(x_adjusted_frames[counter2][num], 0)\n",
    "                                    y_adjusted_frames[counter2][num] = ma.masked_equal(y_adjusted_frames[counter2][num], 0)\n",
    "\n",
    "                                    tlength[counter2][num - 1] = ma.count(x_adjusted_frames[counter2][num])\n",
    "\n",
    "                                plot_traj(x_original_frames[counter2], y_original_frames[counter2], total[counter2], interv, T2plot)\n",
    "                                plt.gcf().clear()\n",
    "                                plot_trajectory_overlay(x_original_frames[counter2], y_original_frames[counter2], 6, 2, 6, Tplot)\n",
    "                                plt.gcf().clear()\n",
    "                                plot_traj_length_histogram(tlength[counter2], max(tlength[counter2]), lenplot)\n",
    "                                plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Datasets Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because my PEG and nPEG datasets had different framerates, I had to analyze the datasets separately.  My code requires all datasets to have the same framerate, and thus they can't be plotted together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates figure\n",
    "\n",
    "line_colors=['g', 'r', 'b', 'c', 'm', 'k']\n",
    "line_kind='-'\n",
    "labels = ['PEG', 'nPEG']\n",
    "label_size=95\n",
    "legend_size=40 \n",
    "tick_size=50\n",
    "line_width=10\n",
    "fig_size=(20, 18)\n",
    "filename = 'test.png'\n",
    "\n",
    "to_graph = {}\n",
    "counter = 0\n",
    "for keys in average_over_slices:\n",
    "    to_graph[counter] = keys\n",
    "    counter = counter + 1\n",
    "for keys in average_over_slices2:\n",
    "    to_graph[counter] = keys\n",
    "    counter = counter + 1\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, dpi=80)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "line_type = [s + line_kind for s in line_colors]\n",
    "ax.plot(time[0:to_frame], average_over_slices[to_graph[0]][0:to_frame], line_type[0], linewidth=line_width, label=labels[0])\n",
    "ax.errorbar(time_SD, average_over_slices[to_graph[0]][SD_frames], all_SD_over_slices[to_graph[0]], fmt='', linestyle='',\n",
    "            capsize=7, capthick=2, elinewidth=2, color=line_colors[0])\n",
    "\n",
    "ax.plot(time2[0:to_frame], average_over_slices2[to_graph[1]][0:to_frame], line_type[1], linewidth=line_width, label=labels[1])\n",
    "ax.errorbar(time_SD2, average_over_slices2[to_graph[1]][SD_frames2], all_SD_over_slices2[to_graph[1]], fmt='', linestyle='',\n",
    "            capsize=7, capthick=2, elinewidth=2, color=line_colors[1])\n",
    "\n",
    "# A few adjustments to prettify the graph\n",
    "for item in ([ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(tick_size)\n",
    "\n",
    "xmajor_ticks = np.arange(0, x_range+0.0001, ticks_x)\n",
    "ymajor_ticks = np.arange(0, y_range+0.0001, ticks_y)\n",
    "\n",
    "ax.set_xticks(xmajor_ticks)\n",
    "plt.xticks(rotation=-30)\n",
    "ax.set_yticks(ymajor_ticks)\n",
    "ax.title.set_fontsize(tick_size)\n",
    "ax.set_xlabel('Time (s)', fontsize=label_size)\n",
    "ax.set_ylabel(r'MSD ($\\mu$m$^2$)', fontsize=label_size)\n",
    "ax.tick_params(direction='out', pad=16)\n",
    "ax.legend(loc=(0.02, 0.75), prop={'size': legend_size})\n",
    "plt.gca().xaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.{}f'.format(dec_x)))\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.{}f'.format(dec_y)))\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.gca().set_xlim([0, x_range+0.0001])\n",
    "plt.gca().set_ylim([0, y_range+0.0001])\n",
    "\n",
    "# Save your figure\n",
    "plt.savefig('{}'.format(filename), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_diffusion_coefficients_gels(channels, surface_functionalities, slices, path, time, time_to_calculate, to_frame, dimension):\n",
    "\n",
    "    \"\"\"\n",
    "    Loads data from csv files and outputs a dictionary following a specified\n",
    "        sample naming convection determined by the input\n",
    "\n",
    "    Parameters:\n",
    "    channels, surface functionalities, media, and concentrations, and replicates\n",
    "        can take ranges or lists.\n",
    "    path is string with substition placeholders for concentration and sample\n",
    "        name (built from channels, surface_functionalities, media,\n",
    "        concentrations, and replicates).\n",
    "\n",
    "    Example:\n",
    "    path = \"./{genotype}/{pup}/{region}/{channel}/geoM2xy_{sample_name}.csv\";\n",
    "    get_data([\"RED\", \"YG\"], [\"WT\", \"KO\", \"HET\"], [\"P1\", \"P2\", \"P3\", \"P4\"],\n",
    "    [\"PEG\", \"noPEG\"], [\"S1\", \"S2\", \"S3\", \"S4\"], [\"cortex\", \"hipp\", \"mid\"],\n",
    "    [1, 2, 3, 4, 5], path)\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}\n",
    "    avg_over_slices_raw = {}\n",
    "    avg_over_pups_raw = {}\n",
    "    names_with_replicates = {}\n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "\n",
    "    diffusion_coef_point_derivative = {}\n",
    "    diffusion_coef_linear_fit = {}\n",
    "\n",
    "    for channel in channels:\n",
    "        for surface_functionality in surface_functionalities:\n",
    "            for slic in slices:\n",
    "                test_value = \"{}_{}_0-4p_agarose_{}\".format(channel, surface_functionality, slic)\n",
    "                avg_over_slices_raw[counter] = test_value\n",
    "                counter = counter + 1\n",
    "                sample_name = test_value\n",
    "                for replicate in replicates:\n",
    "                    sample_name_long = test_value + \"_{}\".format(replicate)\n",
    "                    names_with_replicates[counter2] = sample_name_long\n",
    "                    counter2 = counter2 + 1\n",
    "                filename = path.format(functionality = surface_functionality, slic = slic, sample_name=sample_name)\n",
    "                data[sample_name] = np.genfromtxt(filename, delimiter=\",\")\n",
    "\n",
    "                diffusion_coef_point_derivative[sample_name] =\\\n",
    "                    diffusion_coefficient_point_derivative(data[sample_name], time, time_to_calculate, dimension)\n",
    "                diffusion_coef_linear_fit[sample_name] =\\\n",
    "                    diffusion_coefficient_linear_regression(data[sample_name], time, to_frame, dimension)\n",
    "\n",
    "    return diffusion_coef_point_derivative, diffusion_coef_linear_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_diffusion_coefficients_gels(channels, surface_functionalities, slices, path, time, time_to_calculate, to_frame, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
